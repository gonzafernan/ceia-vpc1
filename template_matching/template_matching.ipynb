{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching y descriptores\n",
    "Objetivos:\n",
    "1. Obtener una detección del logo en cada imagen sin falsos positivos\n",
    "2. Plantear y validar un algoritmo para múltiples detecciones en la imagen `coca_multi.png` con el mismo template del ítem 1\n",
    "3. Generalizar el algoritmo del ítem 2 para todas las imágenes\n",
    "\n",
    "Visualizar los resultados con bounding boxes en cada imagen mostrando el nivel de confianza de la detección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template e imagenes a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_PATH = \"./template/pattern.png\"\n",
    "IMAGES_PATH = \"./images/\"\n",
    "\n",
    "template_color = cv2.imread(TEMPLATE_PATH, cv2.IMREAD_COLOR)\n",
    "images_color = [\n",
    "    cv2.imread(IMAGES_PATH + image_name, cv2.IMREAD_COLOR)\n",
    "    for image_name in os.listdir(path=IMAGES_PATH)\n",
    "    if not \"multi\" in image_name\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesamiento de imagenes\n",
    "<!-- - Se normaliza la imagen mediante una ecualización del histograma -->\n",
    "- Conversión a escala de grises\n",
    "- Aplicación de Gaussian Blue para reducción de ruido\n",
    "- Detección de límites con Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(input_image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Encapsulates the pre-processing on images\"\"\"\n",
    "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 1)\n",
    "    # edges_image = cv2.Canny(blurred_image, threshold1=50, threshold2=150)\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "fig.set_size_inches(15, 5)\n",
    "template1 = preprocess_image(template_color)\n",
    "template2 = -preprocess_image(template_color)\n",
    "axs[0].imshow(cv2.cvtColor(template_color, cv2.COLOR_BGR2RGB))\n",
    "axs[1].imshow(template1, cmap=\"gray\")\n",
    "axs[2].imshow(template2, cmap=\"gray\")\n",
    "axs[0].set_title(\"Original template\")\n",
    "axs[1].set_title(\"Pre-processed template 1\")\n",
    "axs[2].set_title(\"Pre-processed template 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = [preprocess_image(image) for image in images_color]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=len(images_color))\n",
    "fig.set_size_inches(25, 10)\n",
    "for ax_color, ax_preprocess, image_color, input_image in zip(\n",
    "    axs[0][:], axs[1][:], images_color, input_images\n",
    "):\n",
    "    ax_color.imshow(cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB))\n",
    "    ax_preprocess.imshow(input_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de pirámides en el template\n",
    "Se exploro su uso pero no es utilizado en el algoritmo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max width and height of the images to test\n",
    "max_height = max([image.shape[0] for image in input_images])\n",
    "max_width = max([image.shape[1] for image in input_images])\n",
    "min_width = 70\n",
    "\n",
    "# over-sampling\n",
    "template_oversapling = [template1.copy()]\n",
    "while (template_oversapling[-1].shape[0] < max_height) and (\n",
    "    template_oversapling[-1].shape[1] < max_width\n",
    "):\n",
    "    template_oversapling.append(cv2.pyrUp(template_oversapling[-1]))\n",
    "\n",
    "# sub-sampling\n",
    "template_subsapling = [template1.copy()]\n",
    "while template_subsapling[-1].shape[1] > min_width:\n",
    "    template_subsapling.append(cv2.pyrDown(template_subsapling[-1]))\n",
    "\n",
    "# to not repeat the original\n",
    "template_pyramid = template_subsapling + template_oversapling[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUMBER OF TEMPLATES:\", len(template_pyramid))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(template_pyramid))\n",
    "fig.set_size_inches(20, 5)\n",
    "for ax, template in zip(axs, template_pyramid):\n",
    "    ax.imshow(cv2.cvtColor(template, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching\n",
    "Se exploro su uso pero no es utilizado en el algoritmo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    (\"TM_CCOEFF\", cv2.TM_CCOEFF),\n",
    "    (\"TM_CCOEFF_NORMED\", cv2.TM_CCOEFF_NORMED),\n",
    "    (\"TM_CCORR\", cv2.TM_CCORR),\n",
    "    (\"TM_CCORR_NORMED\", cv2.TM_CCORR_NORMED),\n",
    "    (\"TM_SQDIFF\", cv2.TM_SQDIFF),\n",
    "    (\"TM_SQDIFF_NORMED\", cv2.TM_SQDIFF_NORMED),\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(input_images), ncols=len(metrics))\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "for input_image_idx, (input_image, input_image_color) in enumerate(\n",
    "    zip(input_images, images_color)\n",
    "):\n",
    "    for ax, (metric_name, metric_fn) in zip(axs[input_image_idx], metrics):\n",
    "        image = input_image.copy()\n",
    "        max_match_value = 0\n",
    "        max_match = None\n",
    "        for template in template_pyramid:\n",
    "            if (template.shape[0] > image.shape[0]) or (\n",
    "                template.shape[1] > image.shape[1]\n",
    "            ):\n",
    "                continue\n",
    "            match = cv2.matchTemplate(image, template, metric_fn)\n",
    "            min_value, max_value, min_location, max_location = cv2.minMaxLoc(match)\n",
    "            if max_value > max_match_value:\n",
    "                max_match = match\n",
    "\n",
    "        min_value, max_value, min_location, max_location = cv2.minMaxLoc(max_match)\n",
    "        if metric_name in [\"TM_SQDIFF\", \"TM_SQDIFF_NORMED\"]:\n",
    "            top_left = min_location\n",
    "        else:\n",
    "            top_left = max_location\n",
    "        bottom_right = (\n",
    "            top_left[0] + template.shape[1],\n",
    "            top_left[1] + template.shape[0],\n",
    "        )\n",
    "\n",
    "        image_color = input_image_color.copy()\n",
    "        cv2.rectangle(image_color, top_left, bottom_right, 255, 2)\n",
    "        ax.imshow(cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features matching con SIFT\n",
    "Objetivo 1 cumplido: Obtener una detección del logo en cada imagen sin falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(input_images), ncols=1)\n",
    "fig.set_size_inches(10, 20)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "bf_matcher = cv2.BFMatcher()\n",
    "\n",
    "for input_image_idx, (ax, color_image, input_image) in enumerate(\n",
    "    zip(axs, images_color, input_images)\n",
    "):\n",
    "    template = template2 if input_image_idx != 2 else template1\n",
    "    keypoints_template, descriptors_template = sift.detectAndCompute(template, None)\n",
    "    keypoints_input, descriptors_input = sift.detectAndCompute(input_image, None)\n",
    "    matches = bf_matcher.knnMatch(descriptors_template, descriptors_input, k=2)\n",
    "\n",
    "    good_matches = sorted(\n",
    "        [m for m, n in matches if m.distance < 0.8 * n.distance],\n",
    "        key=lambda x: x.distance,\n",
    "    )\n",
    "    template_points = np.float32(\n",
    "        [keypoints_template[m.queryIdx].pt for m in good_matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    input_points = np.float32(\n",
    "        [keypoints_input[m.trainIdx].pt for m in good_matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "\n",
    "    homography, mask = cv2.findHomography(\n",
    "        template_points, input_points, cv2.RANSAC, 3.0\n",
    "    )\n",
    "    draw_params = dict(\n",
    "        matchColor=(0, 255, 255),\n",
    "        singlePointColor=None,\n",
    "        matchesMask=mask.ravel().tolist(),\n",
    "        flags=2,\n",
    "    )\n",
    "\n",
    "    height, width = template.shape[:2]\n",
    "    template_corners = np.float32(\n",
    "        [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    transformed_corners = cv2.perspectiveTransform(template_corners, homography)\n",
    "\n",
    "    plot_image = color_image.copy()\n",
    "    plot_image = cv2.polylines(\n",
    "        plot_image,\n",
    "        [np.int32(transformed_corners)],\n",
    "        isClosed=True,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=3,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    plot_image = cv2.drawMatches(\n",
    "        template,\n",
    "        keypoints_template,\n",
    "        plot_image,\n",
    "        keypoints_input,\n",
    "        good_matches,\n",
    "        None,\n",
    "        **draw_params\n",
    "    )\n",
    "    ax.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "- [Image Processing in OpenCV: Template matching](https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html)\n",
    "- [Image Processing: Image Pyramids](https://docs.opencv.org/4.x/d4/d1f/tutorial_pyramids.html)\n",
    "- [2D Features framework: Basic concepts of the homography explained with code](https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

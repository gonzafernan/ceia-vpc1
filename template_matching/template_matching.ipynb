{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching y descriptores\n",
    "Objetivos:\n",
    "1. Obtener una detección del logo en cada imagen sin falsos positivos\n",
    "2. Plantear y validar un algoritmo para múltiples detecciones en la imagen `coca_multi.png` con el mismo template del ítem 1\n",
    "3. Generalizar el algoritmo del ítem 2 para todas las imágenes\n",
    "\n",
    "Visualizar los resultados con bounding boxes en cada imagen mostrando el nivel de confianza de la detección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template e imagenes a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_PATH = \"./template/pattern.png\"\n",
    "IMAGES_PATH = \"./images/\"\n",
    "\n",
    "template_color = cv2.imread(TEMPLATE_PATH, cv2.IMREAD_COLOR)\n",
    "images_color = [\n",
    "    cv2.imread(IMAGES_PATH + image_name, cv2.IMREAD_COLOR)\n",
    "    for image_name in os.listdir(path=IMAGES_PATH)\n",
    "    if not \"multi\" in image_name\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesamiento de imagenes\n",
    "<!-- - Se normaliza la imagen mediante una ecualización del histograma -->\n",
    "- Conversión a escala de grises\n",
    "- Aplicación de Gaussian Blue para reducción de ruido\n",
    "- Detección de límites con Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(input_image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Encapsulates the pre-processing on images\"\"\"\n",
    "    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (3, 3), 1)\n",
    "    # edges_image = cv2.Canny(gray_image, threshold1=50, threshold2=150)\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=5)\n",
    "fig.set_size_inches(20, 5)\n",
    "template1 = preprocess_image(template_color)\n",
    "template2 = -preprocess_image(template_color)\n",
    "template3 = template1[:,40:350]\n",
    "template4 = template2[:,40:350]\n",
    "axs[0].imshow(cv2.cvtColor(template_color, cv2.COLOR_BGR2RGB))\n",
    "axs[1].imshow(template1, cmap=\"gray\")\n",
    "axs[2].imshow(template2, cmap=\"gray\")\n",
    "axs[3].imshow(template3, cmap=\"gray\")\n",
    "axs[4].imshow(template4, cmap=\"gray\")\n",
    "axs[0].set_title(\"Original template\")\n",
    "axs[1].set_title(\"Pre-processed template 1\")\n",
    "axs[2].set_title(\"Pre-processed template 2\")\n",
    "axs[3].set_title(\"Pre-processed template 3\")\n",
    "axs[4].set_title(\"Pre-processed template 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = [preprocess_image(image) for image in images_color]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=len(images_color))\n",
    "fig.set_size_inches(25, 10)\n",
    "for ax_color, ax_preprocess, image_color, input_image in zip(\n",
    "    axs[0][:], axs[1][:], images_color, input_images\n",
    "):\n",
    "    ax_color.imshow(cv2.cvtColor(image_color, cv2.COLOR_BGR2RGB))\n",
    "    ax_preprocess.imshow(input_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de pirámides en el template\n",
    "Se exploro su uso pero no es utilizado en el algoritmo final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piramide gaussiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max width and height of the images to test\n",
    "max_height = max([image.shape[0] for image in input_images])\n",
    "max_width = max([image.shape[1] for image in input_images])\n",
    "min_width = 70\n",
    "\n",
    "# over-sampling\n",
    "template_oversapling = [template2.copy()]\n",
    "while (template_oversapling[-1].shape[0] < max_height) and (\n",
    "    template_oversapling[-1].shape[1] < max_width\n",
    "):\n",
    "    template_oversapling.append(cv2.pyrUp(template_oversapling[-1]))\n",
    "template_oversapling.reverse()\n",
    "# sub-sampling\n",
    "template_subsapling = [template2.copy()]\n",
    "while template_subsapling[-1].shape[1] > min_width:\n",
    "    template_subsapling.append(cv2.pyrDown(template_subsapling[-1]))\n",
    "# to not repeat the original\n",
    "template_gauss_pyramid =  template_oversapling[:-1] + template_subsapling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUMBER OF TEMPLATES:\", len(template_gauss_pyramid))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(template_gauss_pyramid))\n",
    "fig.set_size_inches(20, 5)\n",
    "for ax, template in zip(axs, template_gauss_pyramid):\n",
    "    ax.imshow(cv2.cvtColor(template, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener mayor granularidad se realizó una piramide con resize e interpolación con INTER_NEAREST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_template_pyramid(template, min_scale=0.2, max_scale=2.5, step=0.1):\n",
    "    \"\"\"Generate a pyramid with intermediate scales for a template.\"\"\"\n",
    "    height, width = template.shape[:2]\n",
    "    pyramid = []\n",
    "    scales = np.arange(min_scale, max_scale + step, step)  # Generate scale factors\n",
    "    for scale in scales:\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        resized = cv2.resize(template, (new_width, new_height), interpolation=cv2.INTER_NEAREST)\n",
    "        pyramid.append(resized)\n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_pyramid = generate_template_pyramid(template3, min_scale=0.2, max_scale=5, step=0.1) + generate_template_pyramid(template4, min_scale=0.2, max_scale=5, step=0.1)\n",
    "print(\"NUMBER OF TEMPLATES:\", len(template_pyramid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching\n",
    "Consideraciones al comparar los resultados obtenidos para diferentes templates:\n",
    "- Las metricas TM_CCOEF y TM_SQDIFF dependen del tamaño del template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_template_matching(\n",
    "    input_image,\n",
    "    template_pyramid,\n",
    "    metric_fn=cv2.TM_CCOEFF_NORMED,\n",
    "    threshold=0.5,\n",
    "    k_targets=1,\n",
    "):\n",
    "    preprocess_input = preprocess_image(input_image)\n",
    "    detected_boxes = []\n",
    "    detected_scores = []\n",
    "\n",
    "    for template in template_pyramid:\n",
    "        if (\n",
    "            template.shape[0] > preprocess_input.shape[0]\n",
    "            or template.shape[1] > preprocess_input.shape[1]\n",
    "        ):\n",
    "            continue\n",
    "        match = cv2.matchTemplate(preprocess_input, template, metric_fn)\n",
    "        _, max_value, _, max_loc = cv2.minMaxLoc(match)\n",
    "        detected_boxes.append(\n",
    "            [max_loc[0], max_loc[1], template.shape[1], template.shape[0]]\n",
    "        )\n",
    "        detected_scores.append(max_value)\n",
    "    print(detected_scores)\n",
    "    if not detected_scores:\n",
    "        return [(-1, -1, -1, -1)]\n",
    "    # Apply Non Maximum Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(detected_boxes, detected_scores, threshold, 0.4, top_k=k_targets)\n",
    "    if len(indices) == 0:\n",
    "        return [(-1, -1, -1, -1)]\n",
    "    return [detected_boxes[index] for index in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación de métodos de template matching haciendo un barrido por la pirámide de templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    # (\"TM_CCOEFF\", cv2.TM_CCOEFF),\n",
    "    (\"TM_CCOEFF_NORMED\", cv2.TM_CCOEFF_NORMED, 0.37),\n",
    "    # (\"TM_CCORR\", cv2.TM_CCORR),\n",
    "    (\"TM_CCORR_NORMED\", cv2.TM_CCORR_NORMED, 0.95),\n",
    "    # (\"TM_SQDIFF\", cv2.TM_SQDIFF), # no good results\n",
    "    # (\"TM_SQDIFF_NORMED\", cv2.TM_SQDIFF_NORMED), # no good results\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(input_images), ncols=len(metrics))\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "for input_image_idx, input_image in enumerate(images_color):\n",
    "    print(input_image_idx)\n",
    "    # template_pyramid = template_pyramid1 if input_image_idx == 2 else template_pyramid3\n",
    "    for ax, (metric_name, metric_fn, threshold) in zip(axs[input_image_idx], metrics):\n",
    "        x, y, w, h = single_template_matching(input_image.copy(), template_pyramid, metric_fn, threshold, k_targets=1)[0]\n",
    "        print(x, y, w, h)\n",
    "        plot_image = input_image.copy()\n",
    "        cv2.rectangle(plot_image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        ax.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = cv2.imread(IMAGES_PATH + \"coca_multi.png\", cv2.IMREAD_COLOR)\n",
    "detections = single_template_matching(input_image.copy(), template_pyramid, threshold=0.5, k_targets=10)\n",
    "print(detections)\n",
    "plot_image = input_image.copy()\n",
    "for x, y, v, h in detections:\n",
    "    cv2.rectangle(plot_image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "plt.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features matching con SIFT\n",
    "Objetivo 1 cumplido: Obtener una detección del logo en cada imagen sin falsos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(input_images), ncols=1)\n",
    "fig.set_size_inches(10, 20)\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "bf_matcher = cv2.BFMatcher()\n",
    "\n",
    "for input_image_idx, (ax, color_image, input_image) in enumerate(\n",
    "    zip(axs, images_color, input_images)\n",
    "):\n",
    "    template = template2 if input_image_idx != 2 else template1\n",
    "    keypoints_template, descriptors_template = sift.detectAndCompute(template, None)\n",
    "    keypoints_input, descriptors_input = sift.detectAndCompute(input_image, None)\n",
    "    matches = bf_matcher.knnMatch(descriptors_template, descriptors_input, k=2)\n",
    "\n",
    "    good_matches = sorted(\n",
    "        [m for m, n in matches if m.distance < 0.8 * n.distance],\n",
    "        key=lambda x: x.distance,\n",
    "    )\n",
    "    template_points = np.float32(\n",
    "        [keypoints_template[m.queryIdx].pt for m in good_matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    input_points = np.float32(\n",
    "        [keypoints_input[m.trainIdx].pt for m in good_matches]\n",
    "    ).reshape(-1, 1, 2)\n",
    "\n",
    "    homography, mask = cv2.findHomography(\n",
    "        template_points, input_points, cv2.RANSAC, 3.0\n",
    "    )\n",
    "    draw_params = dict(\n",
    "        matchColor=(0, 255, 255),\n",
    "        singlePointColor=None,\n",
    "        matchesMask=mask.ravel().tolist(),\n",
    "        flags=2,\n",
    "    )\n",
    "\n",
    "    height, width = template.shape[:2]\n",
    "    template_corners = np.float32(\n",
    "        [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "    ).reshape(-1, 1, 2)\n",
    "    transformed_corners = cv2.perspectiveTransform(template_corners, homography)\n",
    "\n",
    "    plot_image = color_image.copy()\n",
    "    plot_image = cv2.polylines(\n",
    "        plot_image,\n",
    "        [np.int32(transformed_corners)],\n",
    "        isClosed=True,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=3,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    plot_image = cv2.drawMatches(\n",
    "        template,\n",
    "        keypoints_template,\n",
    "        plot_image,\n",
    "        keypoints_input,\n",
    "        good_matches,\n",
    "        None,\n",
    "        **draw_params\n",
    "    )\n",
    "    ax.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "bf_matcher = cv2.BFMatcher()\n",
    "template = template2\n",
    "\n",
    "color_image = cv2.imread(IMAGES_PATH + \"coca_multi.png\", cv2.IMREAD_COLOR)\n",
    "input_image = preprocess_image(color_image)\n",
    "\n",
    "keypoints_template, descriptors_template = sift.detectAndCompute(template, None)\n",
    "keypoints_input, descriptors_input = sift.detectAndCompute(input_image, None)\n",
    "matches = bf_matcher.knnMatch(descriptors_template, descriptors_input, k=2)\n",
    "print(len(matches))\n",
    "print(matches[0])\n",
    "\n",
    "good_matches = sorted(\n",
    "    [m for m, n in matches if m.distance < n.distance],\n",
    "    key=lambda x: x.distance,\n",
    ")\n",
    "\n",
    "template_points = np.float32(\n",
    "    [keypoints_template[m.queryIdx].pt for m in good_matches]\n",
    ").reshape(-1, 1, 2)\n",
    "input_points = np.float32(\n",
    "    [keypoints_input[m.trainIdx].pt for m in good_matches]\n",
    ").reshape(-1, 1, 2)\n",
    "\n",
    "homography, mask = cv2.findHomography(\n",
    "    template_points, input_points, cv2.RANSAC, 5.0\n",
    ")\n",
    "draw_params = dict(\n",
    "    matchColor=(0, 255, 255),\n",
    "    singlePointColor=None,\n",
    "    matchesMask=mask.ravel().tolist(),\n",
    "    flags=2,\n",
    ")\n",
    "\n",
    "plot_image = color_image.copy()\n",
    "plot_image = cv2.drawMatches(\n",
    "    template,\n",
    "    keypoints_template,\n",
    "    plot_image,\n",
    "    keypoints_input,\n",
    "    good_matches,\n",
    "    None,\n",
    "    **draw_params\n",
    ")\n",
    "plt.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_points = np.float32(\n",
    "    [keypoints_input[m.trainIdx].pt for m in good_matches]\n",
    ")\n",
    "\n",
    "# Cluster matches\n",
    "dbscan = DBSCAN(eps=30, min_samples=4).fit(input_points)\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Separate matches into groups\n",
    "unique_labels = set(labels)\n",
    "clusters = {label: [] for label in unique_labels if label != -1}\n",
    "\n",
    "for match, label in zip(good_matches, labels):\n",
    "    if label != -1:  # Exclude noise points\n",
    "        clusters[label].append(match)\n",
    "\n",
    "detections = []\n",
    "for label, cluster_matches in clusters.items():\n",
    "    template_points = np.float32([keypoints_template[m.queryIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "    input_points = np.float32([keypoints_input[m.trainIdx].pt for m in cluster_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Compute homography for this group\n",
    "    homography, mask = cv2.findHomography(template_points, input_points, cv2.RANSAC, 5.0)\n",
    "    if homography is not None:\n",
    "        # Transform template corners\n",
    "        height, width = template.shape[:2]\n",
    "        template_corners = np.float32([[0, 0], [width, 0], [width, height], [0, height]]).reshape(-1, 1, 2)\n",
    "        transformed_corners = cv2.perspectiveTransform(template_corners, homography)\n",
    "        detections.append(transformed_corners)\n",
    "\n",
    "\n",
    "plot_image = color_image.copy()\n",
    "for corners in detections:\n",
    "    cv2.polylines(\n",
    "        plot_image,\n",
    "        [np.int32(corners)],\n",
    "        isClosed=True,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=3,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "plt.imshow(cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "- [Image Processing in OpenCV: Template matching](https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html)\n",
    "- [Image Processing: Image Pyramids](https://docs.opencv.org/4.x/d4/d1f/tutorial_pyramids.html)\n",
    "- [2D Features framework: Basic concepts of the homography explained with code](https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
